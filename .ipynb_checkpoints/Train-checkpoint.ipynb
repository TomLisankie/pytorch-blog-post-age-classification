{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import json\n",
    "import models\n",
    "import datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXAMINE = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ooh shiny new commenting!\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(22)\n",
    "\n",
    "blog_posts_data_dir = \"data/blogs/json-data/\"\n",
    "train_file_name = \"train.json\"\n",
    "test_file_name = \"test.json\"\n",
    "\n",
    "training_set = datasets.BlogPostDataset(blog_posts_data_dir, train_file_name)\n",
    "\n",
    "# Map each word to a unique int value\n",
    "word_to_int = {}\n",
    "for instance in training_set:\n",
    "    for word in instance[\"post\"]:\n",
    "        if word not in word_to_int:\n",
    "            word_to_int[word] = len(word_to_int)\n",
    "\n",
    "def prepare_sequence(seq, word_to_int):\n",
    "    ints = [word_to_int[w] for w in seq]\n",
    "    return torch.tensor(ints, dtype = torch.long)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Key Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121.0\n"
     ]
    }
   ],
   "source": [
    "samples_count = len(training_set)\n",
    "\n",
    "categories_count = len(training_set[0][\"age\"])\n",
    "\n",
    "samples_per_class = {0 : 0, 1 : 0, 2 : 0}\n",
    "for instance in training_set:\n",
    "    for i, a in enumerate(instance[\"age\"]):\n",
    "        if a == 1:\n",
    "            samples_per_class[i] += 1\n",
    "            break\n",
    "\n",
    "median_words_per_sample = np.median([len(instance[\"post\"]) for instance in training_set])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Samples: 526812\n",
      "Number of Categories: 3\n",
      "Samples per Class: {0: 177940, 1: 250672, 2: 98200}\n",
      "Median Words per Sample: 121.0\n",
      "Samples to Words Per Sample Ratio: 4353.818181818182\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Samples:\", samples_count)\n",
    "print(\"Number of Categories:\", categories_count)\n",
    "print(\"Samples per Class:\", samples_per_class)\n",
    "print(\"Median Words per Sample:\", median_words_per_sample)\n",
    "print(\"Samples to Words Per Sample Ratio:\", samples_count / median_words_per_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x274d42a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(list(length_distribution.keys()))\n",
    "plt.xlabel(\"Length of a Sample\")\n",
    "plt.ylabel(\"Number of samples\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "Group Scores Length: 4\n",
      "tensor([[-0.8814, -1.1860, -1.2717],\n",
      "        [-0.9588, -1.1227, -1.2337],\n",
      "        [-0.9526, -1.1911, -1.1700],\n",
      "        [-0.9368, -1.1588, -1.2233]])\n",
      "Group Shape: torch.Size([1, 3])\n",
      "Group: tensor([[ 1,  0,  0]])\n",
      "<class 'torch.Tensor'>\n",
      "Group Scores Length: 4\n",
      "Group Scores Shape: torch.Size([4, 3])\n",
      "Group Score Training: tensor([[-0.8814, -1.1860, -1.2717],\n",
      "        [-0.9588, -1.1227, -1.2337],\n",
      "        [-0.9526, -1.1911, -1.1700],\n",
      "        [-0.9368, -1.1588, -1.2233]])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (4) to match target batch_size (1).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-80ac5cd707b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Group Score Training:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0m_assert_no_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         return F.nll_loss(input, target, self.weight, self.size_average,\n\u001b[0;32m--> 193\u001b[0;31m                           self.ignore_index, self.reduce)\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce)\u001b[0m\n\u001b[1;32m   1328\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m         raise ValueError('Expected input batch_size ({}) to match target batch_size ({}).'\n\u001b[0;32m-> 1330\u001b[0;31m                          .format(input.size(0), target.size(0)))\n\u001b[0m\u001b[1;32m   1331\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1332\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected input batch_size (4) to match target batch_size (1)."
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the model\n",
    "EMBEDDING_DIM = 32\n",
    "HIDDEN_DIM = 15\n",
    "NUM_AGE_GROUPS = 3\n",
    "model = models.BasicLSTMAgeClassifier(EMBEDDING_DIM, len(word_to_int), HIDDEN_DIM, NUM_AGE_GROUPS)\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.1)\n",
    "\n",
    "# WORDS DON'T HAVE AGES, SENTENCES HAVE AGES. I figured this out when I was high. Just thought\n",
    "# where did the \"4\" in the prediction tensor's shape come from?\n",
    "# I need to treat myself like a student and write out my thought process as I'm trying to solve\n",
    "# a problem. I need to ask myself questions.\n",
    "\n",
    "# See what the scores are before training\n",
    "with torch.no_grad():\n",
    "    inputs = prepare_sequence(training_set[EXAMINE][\"post\"], word_to_int)\n",
    "    group_scores = model(inputs)\n",
    "    print(group_scores)\n",
    "\n",
    "for epoch in range(300):\n",
    "    for instance in training_set[ : 4000]:\n",
    "        \n",
    "        # Zero-out the gradients\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Zero-out hidden state from previous instance\n",
    "        model.hidden = model.init_hidden()\n",
    "\n",
    "        sentence_in = prepare_sequence(instance[\"post\"], word_to_int)\n",
    "        group = torch.tensor(instance[\"age\"], dtype = torch.long).unsqueeze(0)\n",
    "        print(\"Group Shape:\", group.shape)\n",
    "        print(\"Group:\", group)\n",
    "\n",
    "        group_scores = model(sentence_in)\n",
    "        print(\"Group Scores Shape:\", group_scores.shape)\n",
    "        print(\"Group Score Training:\", group_scores)\n",
    "        \n",
    "        loss = loss_function(group_scores, group)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# See what the scores are after training\n",
    "with torch.no_grad():\n",
    "    inputs = prepare_sequence(training_set[EXAMINE][\"post\"], word_to_int)\n",
    "    group_scores = model(inputs)\n",
    "    print(group_scores)\n",
    "\n",
    "# TODO: Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
